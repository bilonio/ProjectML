{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ΜΕΡΟΣ Δ\n",
    "________________________________________________________________\n",
    "\n",
    "Σε αυτό το κομμάτι της εργασίας μας δίνεται ένα training dataset με 8743 δείγματα και 224 features ανά δείγμα. Γι' αυτό το σύνολο, μας δίνονται επιπλέον οι ετικέτες για κάθε δείγμα/διάνυσμα χαρακτηρηστικών (*feature vector*), επομένως έχουμε τόσες ετικέτες όσες είναι και τα δείγματά μας. Οι τιμές τους κυμαίνονται από 1,..,5, δηλαδή οι κλάσεις στις οποίες ταξινομούνται τα δείγματα είναι συνολικά 5. Έχοντας, λοιπόν, αυτό το dataset, προσπαθούμε να αναπτύξουμε έναν αλγόριθμο ταξινόμησης με όποια μέθοδο κρίνουμε ότι αποδίδει τα καλύτερα αποτελέσματα. Προκειμένου, να καταλήξουμε στο βέλτιστο μοντέλο, δοκιμάζουμε διάφορες διαδεδομένες τεχνικές εκπαίδευσης και ταξινόμησης, όπου προφανώς κάποιες εφαρμόζουν πολύ καλύτερα από κάποιες άλλες, δεδομένων των αριθμών των δειγμάτων μας και των αριθμών των διαστάσεων των feature μας.\n",
    "Αφού έχουμε εκπαιδεύσει και επαληθεύσει το μοντέλο μας, στη συνέχεια το εφαρμόζουμε σε ένα νέο test dataset που αποτελείται από 6955 δείγματα και για τα οποία δεν γνωρίζουμε εκ των προτέρων την ετικέτα τους. Τέλος, εξάγουμε το διάνυσμα με τις ετικέτες που προέβλεψε το εκπαιδευμένο μοντέλο μας πάνω στα δείγματα του test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "data_train = pd.read_csv('datasetTV.csv', header=None) # Load the training data\n",
    "data_test = pd.read_csv('datasetTest.csv', header=None) # Load the test data\n",
    "X_train = data_train.iloc[:, :-1] # Get the features of the training data\n",
    "y_train = data_train.iloc[:, -1] # Get the labels of the training data\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.8147512864493996 \n",
      "Best model:  RandomForestClassifier(n_estimators=300)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "RFC = RandomForestClassifier() # Create a RandomForestClassifier object\n",
    "\n",
    "# Function to tune the model using GridSearchCV\n",
    "def tune_model(model, param_grid, X_train, X_test, y_train, y_test):\n",
    "    grid = GridSearchCV(model, param_grid, cv=3, n_jobs=-1) # Create a GridSearchCV object\n",
    "    grid.fit(X_train, y_train) # Train the model\n",
    "    y_pred = grid.predict(X_test) # Make predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred) # Calculate accuracy\n",
    "    best_model = grid.best_estimator_ # Get the best model\n",
    "    return accuracy, best_model\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {'n_estimators':[300]} \n",
    "\n",
    "# Tune the model\n",
    "accuracy_RFC, best_model_RFC = tune_model(RFC, param_grid, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the accuracy and the best model\n",
    "print(\"Best accuracy: \", accuracy_RFC, \"\\nBest model: \", best_model_RFC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classifier (Gaussian PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.6986849628359062 \n",
      "Best model:  GaussianNB()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "GNB = GaussianNB() # Create a GaussianNB object\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "\n",
    "param_grid = {}\n",
    "accuracy, best_model = tune_model(GNB, param_grid, X_train, X_test, y_train, y_test)\n",
    "print(\"Best accuracy: \", accuracy, \"\\nBest model: \", best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.8416237850200115 \n",
      "Best model:  KNeighborsClassifier(n_neighbors=14, p=1, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "\n",
    "param_grid = {'n_neighbors': [14], 'algorithm': ['auto'], 'weights': ['distance'],'p': [1]}\n",
    "accuracy, best_model = tune_model(KNN, param_grid, X_train, X_test, y_train, y_test)\n",
    "print(\"Best accuracy: \", accuracy, \"\\nBest model: \", best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppport Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.8650657518582047 \n",
      "Best model:  SVC(C=10, class_weight='balanced', gamma=0.01, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SVC = SVC() # Create SVC Classifier\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {'C': [10], 'gamma': [0.01], 'kernel': ['poly'], 'class_weight': ['balanced']}\n",
    "\n",
    "# Tune the model\n",
    "accuracy_SVC, best_model_SVC = tune_model(SVC, param_grid, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the accuracy and the best model\n",
    "print(\"Best accuracy: \", accuracy_SVC, \"\\nBest model: \", best_model_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy:  0.8502001143510578 \n",
      "Best model:  MLPClassifier(hidden_layer_sizes=(400, 36), random_state=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MLP = MLPClassifier(random_state=1) # Create MLP Classifier\n",
    "\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(400,36)]\n",
    "    }\n",
    "\n",
    "# Tune the model\n",
    "best_accuracy_MLP, best_model_MLP = tune_model(MLP, param_grid, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the accuracy and the best model\n",
    "print(\"Best accuracy: \", best_accuracy_MLP, \"\\nBest model: \", best_model_MLP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MainVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
